from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Spark Text File Example") \
    .getOrCreate()

# Read text files into DataFrame
text_df = spark.read.text('C:\Users\Downloads\Notebookfile.txt')

# Perform computations
line_count = text_df.count()
print(f"Total lines in text files: {line_count}")

# Show some lines from the DataFrame
text_df.show(5, truncate=False)

# Stop Spark session
spark.stop()
 
