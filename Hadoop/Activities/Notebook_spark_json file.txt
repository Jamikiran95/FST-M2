from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Spark JSON File Example") \
    .getOrCreate()

# Read JSON files into DataFrame
json_df = spark.read.json('C:\Users\Downloads\Notebookspark.json"', multiLine=True, inferSchema=True)

# Perform computations
json_df.printSchema()
row_count = json_df.count()
print(f"Total rows in JSON files: {row_count}")

# Show some rows from the DataFrame
json_df.show(5, truncate=False)

# Stop Spark session
spark.stop()
