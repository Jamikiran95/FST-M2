from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Spark CSV File Example") \
    .getOrCreate()

# Read CSV files into DataFrame
csv_df = spark.read.csv('C:\Users\Downloads\Notetextfile.csv', header=True, inferSchema=True)

# Perform computations
csv_df.printSchema()
row_count = csv_df.count()
print(f"Total rows in CSV files: {row_count}")

# Show some rows from the DataFrame
csv_df.show(5, truncate=False)

# Stop Spark session
spark.stop()
